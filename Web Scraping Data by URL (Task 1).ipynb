{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4235d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99838e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"span\", attrs={\"class\":'a-size-large product-title-word-break'})\n",
    "        \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    "\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'class':'a-offscreen'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find(\"span\", attrs={'class':'a-offscreen'}).string.strip()\n",
    "\n",
    "        except:\n",
    "            price = \"\"\n",
    "\n",
    "    return price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\t\n",
    "\n",
    "    return rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\t\n",
    "\n",
    "    return review_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1da7916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # add your user agent \n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.3 Safari/605.1.15', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "    \n",
    "    pages= np.arange(1,21)\n",
    "    for page in pages:\n",
    "        \n",
    "        # The webpage URL\n",
    "        URL = \"https://www.amazon.in/s?k=bags&page=\"+str(page)+\"&qid=1679393196&ref=sr_pg_\"+str(page)\n",
    "        # HTTP Request\n",
    "        webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "        # Soup Object containing all data\n",
    "        soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "        # Fetch links as List of Tag Objects\n",
    "        links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "\n",
    "        # Store the links\n",
    "        links_list = []\n",
    "\n",
    "        Product_Link=[]\n",
    "        Product_Name=[]\n",
    "        Product_price=[]\n",
    "        Rating=[]\n",
    "        Number_of_reviews=[]\n",
    "\n",
    "\n",
    "        # Loop for extracting links from Tag Objects\n",
    "        for link in links:\n",
    "                links_list.append(link.get('href'))\n",
    "\n",
    "        # Loop for extracting product details from each link \n",
    "        for link in links_list:\n",
    "            dlink=\"https://www.amazon.com\" + link\n",
    "            new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "\n",
    "            new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "            Product_Link.append(dlink)\n",
    "            Product_Name.append(get_title(new_soup))\n",
    "            Product_price.append(get_price(new_soup))\n",
    "            Rating.append(get_rating(new_soup))\n",
    "            Number_of_reviews.append(get_review_count(new_soup))\n",
    "\n",
    "        #Exporting to CSV\n",
    "        amazon_df = pd.DataFrame({\"Product Link\":Product_Link,\"Product Name\":Product_Name,\"Product Price\":Product_price,\"Rating\":Rating,\"Number of reviews\":Number_of_reviews})\n",
    "        amazon_df.to_csv(\"Amazon_data(task1).csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
